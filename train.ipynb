{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, Lambda, MaxPooling2D, Dropout, Input\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import tensorflow.keras.backend as K\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "BUCKETS = 5\n",
    "MAX_ANGLE = 450 # May need to confirm this\n",
    "one_hot_length = int(900/BUCKETS)\n",
    "BINS = np.arange(0, MAX_ANGLE - (MAX_ANGLE % BUCKETS) + 2*BUCKETS, BUCKETS)\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 64 # 128, 64, 32, 8, 6\n",
    "DATA_VALUE = 'X'\n",
    "Y_VALUE_1 = 'speed'\n",
    "Y_VALUE_2 = 'steering_angle'\n",
    "timesteps = 100 # 64, 5\n",
    "interval = 10\n",
    "shift_amount = 10\n",
    "number_outputs = int(timesteps/interval)\n",
    "img_shape = (160, 320, 3) #(100, 100, 3) # (3, 160, 320), # \n",
    "predicting_frame_num = 3\n",
    "error_margin = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_list(dataset_folder, size='large'):\n",
    "\n",
    "    assert size in ['large', 'small', 'medium'], \"size must be one of 'large', 'small', 'medium'\"\n",
    "    \n",
    "    files = glob(os.path.join(dataset_folder, '*'))\n",
    "    sorted_files = sorted(files, key = os.path.getsize)\n",
    "\n",
    "    if size == 'small':\n",
    "        return sorted_files[:4]\n",
    "    if size == 'medium':\n",
    "        return sorted_files[:8]\n",
    "    return sorted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_features(example_proto):\n",
    "\n",
    "    features = {'X': tf.io.FixedLenFeature([], dtype=tf.string), \n",
    "                'steering_angle': tf.io.FixedLenFeature([], dtype=tf.float32), \n",
    "                'speed': tf.io.FixedLenFeature([], dtype=tf.float32),}\n",
    "    parsed_features = tf.io.parse_single_example(example_proto, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['X'], tf.uint8)\n",
    "    image = tf.reshape(image, shape=(3, 160, 320))\n",
    "    image = tf.transpose(image, [1, 2, 0])\n",
    "\n",
    "    speed = tf.cast(parsed_features['speed'], tf.float32)\n",
    "    angle = tf.cast(parsed_features['steering_angle'], tf.float32)\n",
    "\n",
    "    return image, (angle, speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_files = get_data_list(dataset_folder=r'D:\\DL-CV-ML Projects\\AUTOV\\data\\datasetB')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size: 15\n",
      "Will result in inputs of: (64, 15, 160, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "block_length = 300\n",
    "interval_stride = 20\n",
    "window_size = int(block_length / interval_stride)\n",
    "print('Window size:', window_size)\n",
    "print('Will result in inputs of:', (BATCH_SIZE, window_size, 160, 320, 3))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dataset_files)\n",
    "dataset = dataset.interleave(tf.data.TFRecordDataset, \n",
    "                             cycle_length=len(dataset_files), \n",
    "                             block_length=block_length, \n",
    "                             num_parallel_calls=tf.data.AUTOTUNE,\n",
    "                             deterministic=True) # Every 300 * len(dataset_files) we repeat. 3300-3599 will be the images that follow 0-299 \n",
    "dataset = dataset.window(size=block_length, shift=block_length, stride=1, drop_remainder=True) # Make every 300 files their own dataset\n",
    "dataset = dataset.map(map_func = lambda x: x.skip( tf.random.uniform((), maxval=interval_stride, dtype=tf.int64) ), num_parallel_calls=tf.data.AUTOTUNE) # Skip value cannot be greater than stride\n",
    "dataset = dataset.flat_map(lambda x: x.window(size=window_size, shift=block_length, stride=interval_stride, drop_remainder=True))\n",
    "dataset = dataset.flat_map(lambda x: x.map(_parse_features, num_parallel_calls=tf.data.AUTOTUNE).batch(window_size))\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds = dataset.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds = list(vds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mimic Dataloader to test if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtificialDataset(tf.data.Dataset):\n",
    "\n",
    "    def _generator(num_samples):\n",
    "        dataset = tf.data.Dataset.range(139)\n",
    "        for i in dataset:\n",
    "            yield(i,)\n",
    "\n",
    "    def __new__(cls, num_samples):\n",
    "        return tf.data.Dataset.from_generator(cls._generator,\n",
    "                                              output_signature = tf.TensorSpec(shape = (1,), dtype = tf.int64),\n",
    "                                              args=(num_samples,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(3)\n",
    "dataset = dataset.interleave(lambda x: ArtificialDataset(x), cycle_length=3, block_length=30, \n",
    "                             num_parallel_calls=tf.data.AUTOTUNE,\n",
    "                             deterministic=True)\n",
    "\n",
    "dataset = dataset.window(size=30, shift=30, stride=1, drop_remainder=True)\n",
    "dataset = dataset.map(lambda d: d.skip( tf.random.uniform((), maxval=5, dtype=tf.int64) ))\n",
    "dataset = dataset.flat_map(lambda d: d.window(size=6, shift=5, stride=5, drop_remainder=True)) # If size = shift = stride = 1 then it will be the same as doing nothing and getting (BS, 1, size) else (BS, window_size, size)\n",
    "# dataset = dataset.flat_map(lambda x: x.batch(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1], dtype=int64), array([6], dtype=int64), array([11], dtype=int64), array([16], dtype=int64), array([21], dtype=int64), array([26], dtype=int64)] 6\n",
      "[array([1], dtype=int64), array([6], dtype=int64), array([11], dtype=int64), array([16], dtype=int64), array([21], dtype=int64), array([26], dtype=int64)] 6\n",
      "[array([1], dtype=int64), array([6], dtype=int64), array([11], dtype=int64), array([16], dtype=int64), array([21], dtype=int64), array([26], dtype=int64)] 6\n",
      "[array([30], dtype=int64), array([35], dtype=int64), array([40], dtype=int64), array([45], dtype=int64), array([50], dtype=int64), array([55], dtype=int64)] 6\n",
      "[array([33], dtype=int64), array([38], dtype=int64), array([43], dtype=int64), array([48], dtype=int64), array([53], dtype=int64), array([58], dtype=int64)] 6\n",
      "[array([31], dtype=int64), array([36], dtype=int64), array([41], dtype=int64), array([46], dtype=int64), array([51], dtype=int64), array([56], dtype=int64)] 6\n",
      "[array([60], dtype=int64), array([65], dtype=int64), array([70], dtype=int64), array([75], dtype=int64), array([80], dtype=int64), array([85], dtype=int64)] 6\n",
      "[array([60], dtype=int64), array([65], dtype=int64), array([70], dtype=int64), array([75], dtype=int64), array([80], dtype=int64), array([85], dtype=int64)] 6\n",
      "[array([60], dtype=int64), array([65], dtype=int64), array([70], dtype=int64), array([75], dtype=int64), array([80], dtype=int64), array([85], dtype=int64)] 6\n",
      "[array([92], dtype=int64), array([97], dtype=int64), array([102], dtype=int64), array([107], dtype=int64), array([112], dtype=int64), array([117], dtype=int64)] 6\n",
      "[array([94], dtype=int64), array([99], dtype=int64), array([104], dtype=int64), array([109], dtype=int64), array([114], dtype=int64), array([119], dtype=int64)] 6\n",
      "[array([94], dtype=int64), array([99], dtype=int64), array([104], dtype=int64), array([109], dtype=int64), array([114], dtype=int64), array([119], dtype=int64)] 6\n",
      "[array([120], dtype=int64), array([125], dtype=int64), array([130], dtype=int64), array([135], dtype=int64), array([121], dtype=int64), array([126], dtype=int64)] 6\n"
     ]
    }
   ],
   "source": [
    "for _, x in enumerate(dataset):\n",
    "    # print(x)\n",
    "    # print(list(list(x)[0]))\n",
    "    j = list(x.as_numpy_iterator())\n",
    "    print(j, len(j))\n",
    "    # print(len(list(x.as_numpy_iterator())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUConv(layers.Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        super(GRUConv, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, x):\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xtra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_length = 300\n",
    "# interval_stride = 10\n",
    "# window_size = int(block_length / interval_stride)\n",
    "# shift = 5\n",
    "# print(window_size)\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(dataset_files)\n",
    "# dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=len(dataset_files), block_length=block_length) # Every 300 * len(dataset_files) we repeat. 3300-3599 will be the images that follow 0-299 \n",
    "# dataset = tf.data.Dataset.from_tensor_slices([dataset])\n",
    "# dataset = dataset.flat_map(lambda d: d.skip(tf.random.uniform((), maxval=9, dtype=tf.int64)))\n",
    "# dataset = dataset.map(_parse_features, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# dataset = dataset.window(window_size, shift=shift, stride=interval_stride, drop_remainder=True)\n",
    "# Batch\n",
    "# Shuffle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
