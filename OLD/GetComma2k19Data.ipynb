{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qAAMGnNVi9XJ"},"outputs":[],"source":["import os\n","import glob\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tqdm.autonotebook import tqdm\n","import imageio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQLvMXkihEFT"},"outputs":[],"source":["train = ['Chunk_3', 'Chunk_4', 'Chunk_6', 'Chunk_7', 'Chunk_9', 'Chunk_10']\n","val = ['Chunk_5', 'Chunk_8']\n","test = ['Chunk_1', 'Chunk_2']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U8vag2Z0j8yn"},"outputs":[],"source":["def add_zero(x):\n","\n","  num = x.split('/')[-1] \n","  if len(num) == 2:\n","    return x\n","  else:\n","    return x[:-1] + '0' + num"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5GNIRrq2TMet"},"outputs":[],"source":["def _bytes_feature(value):\n","    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def _float_feature(value):\n","    \"\"\"Returns a float_list from a float / double.\"\"\"\n","    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n","\n","def _int64_feature(value):\n","    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EUX81fW-Y3Ie"},"outputs":[],"source":["def serialize_example(example):\n","    \"\"\"Serialize an item in a dataset\n","    Arguments:\n","      example {[list]} -- list of dictionaries with fields \"name\" , \"_type\", and \"data\"\n","\n","    Returns:\n","      [type] -- [description]\n","    \"\"\"\n","    dset_item = {}\n","    for key in example.keys():\n","        dset_item[key] = example[key][\"_type\"](example[key][\"data\"])\n","        example_proto = tf.train.Example(features=tf.train.Features(feature=dset_item))\n","    return example_proto.SerializeToString()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QcrpHWHOnVzg"},"outputs":[],"source":["finished_val = ['99c94dc769b5d96e|2018-07-03--14-38-26', '99c94dc769b5d96e|2018-07-06--11-17-49', '99c94dc769b5d96e|2018-07-05--20-49-41', \n","                '99c94dc769b5d96e|2018-07-06--09-43-54', '99c94dc769b5d96e|2018-07-05--10-05-06', '99c94dc769b5d96e|2018-07-06--01-15-15', \n","                '99c94dc769b5d96e|2018-07-04--00-20-19', '99c94dc769b5d96e|2018-07-05--19-49-34', '99c94dc769b5d96e|2018-07-05--16-30-16',\n","                '99c94dc769b5d96e|2018-07-06--12-32-39']"]},{"cell_type":"markdown","source":["First handle segments"],"metadata":{"id":"zmtX2RYfn-gt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsLSUv_MF8d9"},"outputs":[],"source":["for chunk_dir in glob.glob('/content/drive/Shareddrives/ELEC 494 - Ω2Ω/Data/Comma2k19/*'): # Chunk Directory\n","\n","  if chunk_dir.split('/')[-1] in test:\n","    print('In chunk: ', chunk_dir)\n","\n","    for segment in os.listdir(chunk_dir): # Weird number Directory\n","\n","        # if segment in finished_val:\n","        #   continue\n","        print(f'Currently on {segment}')\n","\n","        # Prepare List\n","        speed_list = []\n","        angle_list = []\n","        video_list = []\n","\n","        # Set up files in order\n","        segment_files = glob.glob(os.path.join(chunk_dir, segment, '*'))\n","        segment_files = sorted(list(map(add_zero, segment_files))) # Sort the files but need to add a 0 bc for example 11 is considered lower than 9 but not 09\n","        print('Order of files: ', list(map(lambda x: x.split('/')[-1], segment_files)))\n","\n","        # Iterate through the numbers within each file\n","        for segment_number_file in segment_files:\n","            if segment_number_file.split('/')[-1][0] == '0': # remove the 0's\n","                segment_number_file = segment_number_file.replace('/0', '/')\n","\n","            # Load arrays for each number \n","            speed_values = np.load(os.path.join(segment_number_file, 'processed_log/CAN/speed/value'), mmap_mode='r')\n","            speed_values = speed_values.reshape(-1,)\n","            steering_angle_values = np.load(os.path.join(segment_number_file, 'processed_log/CAN/steering_angle/value'), mmap_mode='r')\n","            steering_angle_values = steering_angle_values.reshape(-1,)\n","\n","            # video_numpy = video_to_numpy(os.path.join(segment_number_file, 'video.hevc'))\n","            try:\n","              vid = imageio.(os.path.join(segment_number_file, 'video.hevc'), 'ffmpeg')\n","              data = np.sget_readertack(list(vid.iter_data()))\n","              video_numpy = tf.image.resize(data, [128, 128]).numpy().astype('uint8')\n","            except:\n","              print(f\"Couldn't open {os.path.join(segment_number_file, 'video.hevc')}\")\n","              continue\n","\n","            idxs_speed = np.linspace(0, speed_values.shape[0] - 1, video_numpy.shape[0]).astype(\"int\")\n","            idxs_angle = np.linspace(0, steering_angle_values.shape[0] - 1, video_numpy.shape[0]).astype(\"int\")\n","\n","            # Append to list\n","            speed_list.append(speed_values[idxs_speed])\n","            angle_list.append(steering_angle_values[idxs_angle])\n","            video_list.append(video_numpy)\n","\n","        # Gather all the items within the overall file\n","        speed_array = np.concatenate(speed_list)\n","        angle_array = np.concatenate(angle_list)\n","        frames_array = np.concatenate(video_list)\n","\n","        num_of_items = frames_array.shape[0]\n","\n","        # Write TFRecords\n","        # print(f'Writing {segment} TFRecord File')\n","        with tf.io.TFRecordWriter(f'/content/drive/Shareddrives/ELEC 494 - Ω2Ω/Data/comma2k19TF/test/{segment}.tfrecord') as writer:\n","\n","            for row in tqdm(range(num_of_items)):\n","\n","              speed = speed_array[row]\n","              angle = angle_array[row]        \n","              img_resized = frames_array[row]\n","\n","              fields = {\n","                  'X': {'data': img_resized.flatten().tobytes(), '_type': _bytes_feature},\n","                  'speed': {'data': speed, '_type': _float_feature}, \n","                  'steering_angle': {'data': angle, '_type': _float_feature},\n","                  }\n","\n","              example = serialize_example(fields)\n","              writer.write(example)\n","\n","    print('------------------------------------------------------------------------------------------------------------------------------')"]},{"cell_type":"code","source":["len(os.listdir('/content/drive/Shareddrives/ELEC 494 - Ω2Ω/Data/comma2k19TF/test')) + len(os.listdir('/content/drive/Shareddrives/ELEC 494 - Ω2Ω/Data/comma2k19TF/val')) + len(os.listdir('/content/drive/Shareddrives/ELEC 494 - Ω2Ω/Data/comma2k19TF/train'))"],"metadata":{"id":"kwLk5Zr__MTU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["directory = '/content/drive/Shareddrives/ELEC 494 - Ω2Ω/Data/comma2k19TF/val'\n","total_size = 0\n","\n","for dirpath, dirnames, filenames in os.walk(directory):\n","    for file in filenames:\n","        file_path = os.path.join(dirpath, file)\n","\n","        if not os.path.islink(file_path):\n","            total_size += os.path.getsize(file_path)\n","\n","print(\"Total size:\", total_size/1e9, \"bytes\")"],"metadata":{"id":"9EXCYy6-_lts"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Combine segments into chunks I believe"],"metadata":{"id":"0fDx5fnBoBOB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RatxsgfqYOsi"},"outputs":[],"source":["for chunk in glob.glob('/content/drive/Shareddrives/ELEC 494 - Ω2Ω/Data/Comma2k19/*'): # Chunk Directory\n","\n","  print('In chunk: ', chunk)\n","  \n","  chunk_name = chunk.split('/')[-1]\n","  if chunk_name in test:\n","      i = 0\n","      for item in sorted(glob.glob(f'{chunk}/*/*')):\n","        \n","        name = chunk_name + '_' + str(i)\n","\n","        video_path = os.path.join(item, 'video.hevc')\n","        angle_path = os.path.join(item, 'processed_log/CAN/steering_angle/value')\n","        speed_path = os.path.join(item, 'processed_log/CAN/speed/value')\n","\n","        vid = imageio.get_reader(video_path, 'ffmpeg')\n","        data = np.stack(list(vid.iter_data()))\n","        img_data = tf.image.resize(data, [128, 128]).numpy().astype('uint8')\n","\n","        speed_values = np.load(speed_path,  mmap_mode='r')\n","        speed_values = speed_values.reshape(-1,)\n","        angle_values = np.load(angle_path,  mmap_mode='r')\n","        angle_values = angle_values.reshape(-1,)\n","\n","        if speed_values.shape[0] != angle_values.shape[0]:\n","          print(f'Speed and Angle arrays dont have same shape for {item}')\n","          print(f'speed shape: {speed_values.shape[0]}, angle shape: {angle_values.shape[0]}')\n","\n","          min_value = min(speed_values.shape[0], angle_values.shape[0])\n","          idx_speed = np.linspace(0, speed_values.shape[0]-1, min_value).astype(\"int\")\n","          idx_angle = np.linspace(0, angle_values.shape[0]-1, min_value).astype(\"int\")\n","\n","          speed_values = speed_values[idx_speed]\n","          angle_values = angle_values[idx_angle]\n","\n","        idxs = np.linspace(0, speed_values.shape[0] - 1, img_data.shape[0]).astype(\"int\")\n","\n","        speed_values = speed_values[idxs]\n","        angle_values = angle_values[idxs]\n","        assert speed_values.shape[0] == angle_values.shape[0] == img_data.shape[0], 'Shapes need to be the same'\n","\n","        num_of_items = img_data.shape[0]\n","        with tf.io.TFRecordWriter(f'/content/drive/Shareddrives/ELEC 494 - Ω2Ω/Data/comma2k19TF/test/{name}.tfrecord') as writer:\n","\n","            for row in tqdm(range(num_of_items)):\n","\n","              speed = speed_values[row]\n","              angle = angle_values[row]        \n","              img_resized = img_data[row]\n","              \n","              fields = {\n","                  'X': {'data': img_resized.flatten().tobytes(), '_type': _bytes_feature},\n","                  'speed': {'data': speed, '_type': _float_feature}, \n","                  'steering_angle': {'data': angle, '_type': _float_feature},\n","                  }\n","\n","              example = serialize_example(fields)\n","              writer.write(example)\n","        i+=1\n","      break "]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"GetComma2k19Data.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}